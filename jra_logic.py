# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qlLklcwzaVXyI8h0riG-ygLbJHuSOMNQ
"""

# jra_logic.py
!pip install rapidfuzz
import pandas as pd
from typing import Optional, Dict, Any, List
from rapidfuzz import process, fuzz

# Aturan JRA
JRA_RULES = [
    {"label": "JRA 1994", "start": 1994, "end": 2001, "excel": 1994},
    {"label": "JRA 2002", "start": 2002, "end": 2005, "excel": 2002},
    {"label": "JRA 2006", "start": 2006, "end": 2018, "excel": 2006},
    {"label": "JRA 2019", "start": 2019, "end": 2026, "excel": 2019},
]

def get_jra_info(year: int) -> Optional[Dict[str,Any]]:
    """Return rule dict jika year masuk ke salah satu JRA_RULES, else None."""
    for rule in JRA_RULES:
        if rule["start"] <= year <= rule["end"]:
            return rule
    return None

def normalize_kb(df: pd.DataFrame) -> pd.DataFrame:
    """Bersihkan dataframe: pilih kolom penting, ubah tipe, drop NaN di JRA."""
    # drop unnamed cols
    df = df.loc[:, df.columns.str.strip().isin(["Jenis Dokumen", "JRA", "Kode"])]
    # ensure columns exist
    required = {"Jenis Dokumen", "JRA", "Kode"}
    if not required.issubset(set(df.columns)):
        raise ValueError(f"Knowledge base harus mengandung kolom: {required}. Kolom saat ini: {list(df.columns)}")
    # strip strings
    df["Jenis Dokumen"] = df["Jenis Dokumen"].astype(str).str.strip()
    # convert JRA to integer-ish; allow NaN
    df["JRA"] = pd.to_numeric(df["JRA"], errors="coerce").astype("Int64")
    # Kode as string
    df["Kode"] = df["Kode"].astype(str).str.strip()
    # drop rows with null JRA or empty Jenis Dokumen
    df = df.dropna(subset=["JRA", "Jenis Dokumen"])
    return df

def match_by_keywords(judul: str, candidates: pd.Series, min_token_match: int = 1) -> List[int]:
    """
    Token match: bagi judul jadi kata, kembalikan indices candidates yang punya >=min_token_match token.
    candidates: pd.Series of strings
    returns: list of indices (int positional)
    """
    tokens = [t for t in str(judul).lower().split() if t.strip()]
    if not tokens:
        return []
    matched_idx = []
    for i, txt in enumerate(candidates.str.lower()):
        if sum(1 for tk in tokens if tk in txt) >= min_token_match:
            matched_idx.append(i)
    return matched_idx

def fuzzy_best_match(judul: str, choices: List[str], score_cutoff: int = 70):
    """Return best (choice, score, index) using rapidfuzz or None if below cutoff."""
    if not choices:
        return None
    match = process.extractOne(judul, choices, scorer=fuzz.token_sort_ratio)
    if match and match[1] >= score_cutoff:
        # match = (choice, score, idx)
        return match
    return None

def find_codes_for_year_and_title(df_kb: pd.DataFrame, excel_jra: int, judul: str,
                                  min_token_match: int = 1, fuzzy_threshold: int = 75):
    """
    - df_kb: normalized kb
    - excel_jra: integer like 2006
    - judul: user input
    Returns DataFrame of matches (can be empty).
    """
    df_year = df_kb[df_kb["JRA"] == excel_jra].copy()
    if df_year.empty:
        return df_year  # empty DataFrame

    # token match first
    idxs = match_by_keywords(judul, df_year["Jenis Dokumen"], min_token_match=min_token_match)
    if idxs:
        return df_year.iloc[idxs]

    # fallback: fuzzy best match (if any)
    choices = df_year["Jenis Dokumen"].tolist()
    match = fuzzy_best_match(judul, choices, score_cutoff=fuzzy_threshold)
    if match:
        choice, score, idx_in_choices = match
        # find the row
        # idx_in_choices is index in choices list -> get corresponding .iloc index
        return df_year.iloc[[idx_in_choices]].assign(_fuzzy_score=score)

    # no match
    return df_year.iloc[0:0]  # empty but same columns